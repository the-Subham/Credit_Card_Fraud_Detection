{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:/Users/KIIT/Desktop/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Display Top 5 Rows of The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check Last 5 Rows of The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Shape of Our Dataset (Number of Rows And Number of Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows 284807\n",
      "Number of Columns 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Rows\",data.shape[0])\n",
    "print(\"Number of Columns\",data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get Information About Our Dataset Like Total Number Rows, Total Number of Columns, Datatypes of Each Column And Memory Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check Null Values In The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount']=sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "284807- 275663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Not Handling Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Store Feature Matrix In X And Response (Target) In Vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Splitting The Dataset Into The Training Set And Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "# Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample=normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([normal_sample,fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.134001</td>\n",
       "      <td>0.260498</td>\n",
       "      <td>0.228996</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>-0.105927</td>\n",
       "      <td>-0.460151</td>\n",
       "      <td>0.175176</td>\n",
       "      <td>0.075888</td>\n",
       "      <td>-0.254153</td>\n",
       "      <td>0.155349</td>\n",
       "      <td>1.576690</td>\n",
       "      <td>0.375365</td>\n",
       "      <td>-1.627572</td>\n",
       "      <td>1.048515</td>\n",
       "      <td>0.472221</td>\n",
       "      <td>-0.095750</td>\n",
       "      <td>-0.166828</td>\n",
       "      <td>-0.524060</td>\n",
       "      <td>-0.231743</td>\n",
       "      <td>-0.255600</td>\n",
       "      <td>-0.308669</td>\n",
       "      <td>-1.006426</td>\n",
       "      <td>0.197540</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>0.221775</td>\n",
       "      <td>-0.737237</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>-0.306412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.869777</td>\n",
       "      <td>0.593563</td>\n",
       "      <td>0.696037</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>1.447008</td>\n",
       "      <td>-0.822508</td>\n",
       "      <td>0.751636</td>\n",
       "      <td>-0.065105</td>\n",
       "      <td>-0.867552</td>\n",
       "      <td>-0.220365</td>\n",
       "      <td>1.328039</td>\n",
       "      <td>1.009361</td>\n",
       "      <td>0.196914</td>\n",
       "      <td>0.556722</td>\n",
       "      <td>-0.551720</td>\n",
       "      <td>-0.168254</td>\n",
       "      <td>-0.627222</td>\n",
       "      <td>-0.296290</td>\n",
       "      <td>-0.934626</td>\n",
       "      <td>-0.325261</td>\n",
       "      <td>0.226080</td>\n",
       "      <td>0.684077</td>\n",
       "      <td>-0.242755</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>-0.360603</td>\n",
       "      <td>-0.580343</td>\n",
       "      <td>0.115603</td>\n",
       "      <td>0.133778</td>\n",
       "      <td>-0.351270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.710087</td>\n",
       "      <td>-0.931403</td>\n",
       "      <td>-0.914705</td>\n",
       "      <td>0.131475</td>\n",
       "      <td>-0.415795</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>-0.415655</td>\n",
       "      <td>0.128321</td>\n",
       "      <td>1.287239</td>\n",
       "      <td>-0.095317</td>\n",
       "      <td>-0.133898</td>\n",
       "      <td>0.221504</td>\n",
       "      <td>-1.004020</td>\n",
       "      <td>0.495947</td>\n",
       "      <td>0.582773</td>\n",
       "      <td>0.784158</td>\n",
       "      <td>-1.198975</td>\n",
       "      <td>1.003180</td>\n",
       "      <td>0.492267</td>\n",
       "      <td>0.053993</td>\n",
       "      <td>-0.058519</td>\n",
       "      <td>-0.492673</td>\n",
       "      <td>0.089127</td>\n",
       "      <td>-1.122373</td>\n",
       "      <td>-0.364126</td>\n",
       "      <td>-0.902315</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.021610</td>\n",
       "      <td>0.307814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.665162</td>\n",
       "      <td>-0.953577</td>\n",
       "      <td>-0.771738</td>\n",
       "      <td>0.417172</td>\n",
       "      <td>-0.371509</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>-0.540726</td>\n",
       "      <td>-0.017112</td>\n",
       "      <td>2.153092</td>\n",
       "      <td>-0.209006</td>\n",
       "      <td>0.902207</td>\n",
       "      <td>-1.979913</td>\n",
       "      <td>1.800537</td>\n",
       "      <td>1.568429</td>\n",
       "      <td>-0.458434</td>\n",
       "      <td>1.020766</td>\n",
       "      <td>-0.529684</td>\n",
       "      <td>1.241580</td>\n",
       "      <td>-0.004768</td>\n",
       "      <td>0.194118</td>\n",
       "      <td>0.131451</td>\n",
       "      <td>0.297210</td>\n",
       "      <td>-0.107498</td>\n",
       "      <td>-1.045286</td>\n",
       "      <td>-0.319269</td>\n",
       "      <td>0.522597</td>\n",
       "      <td>-0.096091</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>0.446388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.795322</td>\n",
       "      <td>0.081238</td>\n",
       "      <td>2.210568</td>\n",
       "      <td>0.268145</td>\n",
       "      <td>-0.506875</td>\n",
       "      <td>-0.303840</td>\n",
       "      <td>-0.180829</td>\n",
       "      <td>0.085540</td>\n",
       "      <td>0.248346</td>\n",
       "      <td>-0.470248</td>\n",
       "      <td>0.016654</td>\n",
       "      <td>0.540836</td>\n",
       "      <td>0.373179</td>\n",
       "      <td>-0.446605</td>\n",
       "      <td>0.692985</td>\n",
       "      <td>-0.971320</td>\n",
       "      <td>0.801677</td>\n",
       "      <td>-0.714839</td>\n",
       "      <td>0.799956</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.210198</td>\n",
       "      <td>0.869922</td>\n",
       "      <td>-0.118656</td>\n",
       "      <td>0.744594</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>1.259841</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.128346</td>\n",
       "      <td>-0.201742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.134001  0.260498  0.228996  0.998521 -0.105927 -0.460151  0.175176   \n",
       "1 -0.869777  0.593563  0.696037  0.003785  1.447008 -0.822508  0.751636   \n",
       "2  1.710087 -0.931403 -0.914705  0.131475 -0.415795  0.084214 -0.415655   \n",
       "3  1.665162 -0.953577 -0.771738  0.417172 -0.371509  0.250856 -0.540726   \n",
       "4 -0.795322  0.081238  2.210568  0.268145 -0.506875 -0.303840 -0.180829   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.075888 -0.254153  0.155349  1.576690  0.375365 -1.627572  1.048515   \n",
       "1 -0.065105 -0.867552 -0.220365  1.328039  1.009361  0.196914  0.556722   \n",
       "2  0.128321  1.287239 -0.095317 -0.133898  0.221504 -1.004020  0.495947   \n",
       "3 -0.017112  2.153092 -0.209006  0.902207 -1.979913  1.800537  1.568429   \n",
       "4  0.085540  0.248346 -0.470248  0.016654  0.540836  0.373179 -0.446605   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  0.472221 -0.095750 -0.166828 -0.524060 -0.231743 -0.255600 -0.308669   \n",
       "1 -0.551720 -0.168254 -0.627222 -0.296290 -0.934626 -0.325261  0.226080   \n",
       "2  0.582773  0.784158 -1.198975  1.003180  0.492267  0.053993 -0.058519   \n",
       "3 -0.458434  1.020766 -0.529684  1.241580 -0.004768  0.194118  0.131451   \n",
       "4  0.692985 -0.971320  0.801677 -0.714839  0.799956  0.054227  0.210198   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -1.006426  0.197540  0.118126  0.221775 -0.737237  0.005801  0.010478   \n",
       "1  0.684077 -0.242755  0.053508 -0.360603 -0.580343  0.115603  0.133778   \n",
       "2 -0.492673  0.089127 -1.122373 -0.364126 -0.902315  0.014388 -0.021610   \n",
       "3  0.297210 -0.107498 -1.045286 -0.319269  0.522597 -0.096091 -0.040264   \n",
       "4  0.869922 -0.118656  0.744594 -0.504294  1.259841  0.014692  0.128346   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.306412      0  \n",
       "1 -0.351270      0  \n",
       "2  0.307814      0  \n",
       "3  0.446388      0  \n",
       "4 -0.201742      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop('Class',axis=1)\n",
    "y = new_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421052631578948"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421052631578948"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789473684210527"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789473684210527"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315789473684211"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9320388349514563"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365853658536586"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9526315789473684"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894736842105263"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215686274509803"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543147208121827"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "              \"ACC\":[accuracy_score(y_test,y_pred1)*100,\n",
    "                     accuracy_score(y_test,y_pred2)*100,\n",
    "                     accuracy_score(y_test,y_pred3)*100\n",
    "                    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>94.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>93.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>95.263158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  94.210526\n",
       "1     DT  93.157895\n",
       "2     RF  95.263158"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(final_data['Models'],final_data['ACC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,y_res = SMOTE().fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_res,y_res,test_size=0.20,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443475416984629"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972524604110675"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144592113157464"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425985270141114"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981739888804099"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973138770917275"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990364161954802"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981744035022388"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier()\n",
    "#rf.fit(X_train,y_train)\n",
    "from joblib import parallel_backend\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Implement parallel processing\n",
    "with parallel_backend('multiprocessing'):\n",
    "    # Define the randomized search cross-validation\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf1,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "              \"ACC\":[accuracy_score(y_test,y_pred1)*100,\n",
    "                     accuracy_score(y_test,y_pred2)*100,\n",
    "                     accuracy_score(y_test,y_pred3)*100\n",
    "                    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(final_data['Models'],final_data['ACC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf1 = RandomForestClassifier()\n",
    "#rf1.fit(X_res,y_res)\n",
    "\n",
    "rf1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Implement parallel processing\n",
    "with parallel_backend('multiprocessing'):\n",
    "    # Define the randomized search cross-validation\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf1,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf1,\"credit_card_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"credit_card_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred == 0:\n",
    "    print(\"Normal Transcation\")\n",
    "else:\n",
    "    print(\"Fraudulent Transcation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import joblib\n",
    "\n",
    "def show_entry_fields():\n",
    "    v1=float(e1.get())\n",
    "    v2=float(e2.get())\n",
    "    v3=float(e3.get())\n",
    "    v4=float(e4.get())\n",
    "    v5=float(e5.get())\n",
    "    v6=float(e6.get())\n",
    "\n",
    "    v7=float(e7.get())\n",
    "    v8=float(e8.get())\n",
    "    v9=float(e9.get())\n",
    "    v10=float(e10.get())\n",
    "    v11=float(e11.get())\n",
    "    v12=float(e12.get())\n",
    "\n",
    "    v13=float(e13.get())\n",
    "    v14=float(e14.get())\n",
    "    v15=float(e15.get())\n",
    "    v16=float(e16.get())\n",
    "    v17=float(e17.get())\n",
    "    v18=float(e18.get())\n",
    "\n",
    "\n",
    "    v19=float(e19.get())\n",
    "    v20=float(e20.get())\n",
    "    v21=float(e21.get())\n",
    "    v22=float(e22.get())\n",
    "    v23=float(e23.get())\n",
    "    v24=float(e24.get())\n",
    "\n",
    "\n",
    "    v25=float(e25.get())\n",
    "    v26=float(e26.get())\n",
    "    v27=float(e27.get())\n",
    "    v28=float(e28.get())\n",
    "    v29=float(e29.get())\n",
    "\n",
    "\n",
    "    model = joblib.load('model_credit.pkl')\n",
    "    y_pred = model.predict([[v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12,v13,v14,v15,v16,v17,v18,\n",
    "                                v19,v20,v21,v22,v23,v24,v25,v26,v27,v28,v29]])\n",
    "    list1=[v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12,v13,v14,v15,v16,v17,v18,\n",
    "                                v19,v20,v21,v22,v23,v24,v25,v26,v27,v28,v29]\n",
    "\n",
    "    result = []\n",
    "    if y_pred ==0:\n",
    "\n",
    "        result.append(\"Normal Transcation\")\n",
    "    else:\n",
    "\n",
    "        result.append(\"Fraudulent Transcation\")\n",
    "    print(\"######################################\")\n",
    "    print(\"Credit Card Fraud Detection System\", result)\n",
    "    print(\"######################################\")\n",
    "\n",
    "\n",
    "\n",
    "    Label(master, text=\"Final Prediction from the model - credit card fraud detection\").grid(row=31)\n",
    "    Label(master, text=result).grid(row=32)\n",
    "\n",
    "\n",
    "\n",
    "master = Tk()\n",
    "master.title(\"Credit Card Fraud Detection System\")\n",
    "\n",
    "\n",
    "label = Label(master, text = \"Credit Card Fraud Detection System\"\n",
    "                          , bg = \"black\", fg = \"white\",width = 30).grid(row=0,columnspan=2)\n",
    "\n",
    "\n",
    "Label(master, text=\"Enter value of V1\").grid(row=1)\n",
    "Label(master, text=\"Enter value of V2\").grid(row=2)\n",
    "Label(master, text=\"Enter value of V3\").grid(row=3)\n",
    "Label(master, text=\"Enter value of V4\").grid(row=4)\n",
    "Label(master, text=\"Enter value of V5\").grid(row=5)\n",
    "Label(master, text=\"Enter value of V6\").grid(row=6)\n",
    "\n",
    "Label(master, text=\"Enter value of V7\").grid(row=7)\n",
    "Label(master, text=\"Enter value of V8\").grid(row=8)\n",
    "Label(master, text=\"Enter value of V9\").grid(row=9)\n",
    "Label(master, text=\"Enter value of V10\").grid(row=10)\n",
    "Label(master, text=\"Enter value of V11\").grid(row=11)\n",
    "Label(master, text=\"Enter value of V12\").grid(row=12)\n",
    "\n",
    "Label(master, text=\"Enter value of V13\").grid(row=13)\n",
    "Label(master, text=\"Enter value of V14\").grid(row=14)\n",
    "Label(master, text=\"Enter value of V15\").grid(row=15)\n",
    "Label(master, text=\"Enter value of V16\").grid(row=16)\n",
    "Label(master, text=\"Enter value of V17\").grid(row=17)\n",
    "Label(master, text=\"Enter value of V18\").grid(row=18)\n",
    "\n",
    "Label(master, text=\"Enter value of V19\").grid(row=19)\n",
    "Label(master, text=\"Enter value of V20\").grid(row=20)\n",
    "Label(master, text=\"Enter value of V21\").grid(row=21)\n",
    "Label(master, text=\"Enter value of V22\").grid(row=22)\n",
    "Label(master, text=\"Enter value of V23\").grid(row=23)\n",
    "Label(master, text=\"Enter value of V24\").grid(row=24)\n",
    "\n",
    "Label(master, text=\"Enter value of V25\").grid(row=25)\n",
    "Label(master, text=\"Enter value of V26\").grid(row=26)\n",
    "Label(master, text=\"Enter value of V27\").grid(row=27)\n",
    "Label(master, text=\"Enter value of V28\").grid(row=28)\n",
    "Label(master, text=\"Enter value of V29\").grid(row=29)\n",
    "\n",
    "e1 = Entry(master)\n",
    "e2 = Entry(master)\n",
    "e3 = Entry(master)\n",
    "e4 = Entry(master)\n",
    "e5 = Entry(master)\n",
    "e6 = Entry(master)\n",
    "\n",
    "e7 = Entry(master)\n",
    "e8 = Entry(master)\n",
    "e9 = Entry(master)\n",
    "e10 = Entry(master)\n",
    "e11 = Entry(master)\n",
    "e12 = Entry(master)\n",
    "\n",
    "e13 = Entry(master)\n",
    "e14 = Entry(master)\n",
    "e15 = Entry(master)\n",
    "e16 = Entry(master)\n",
    "e17 = Entry(master)\n",
    "e18= Entry(master)\n",
    "\n",
    "e19 = Entry(master)\n",
    "e20 = Entry(master)\n",
    "e21 = Entry(master)\n",
    "e22 = Entry(master)\n",
    "e23= Entry(master)\n",
    "e24 = Entry(master)\n",
    "\n",
    "\n",
    "e25 = Entry(master)\n",
    "e26= Entry(master)\n",
    "e27 = Entry(master)\n",
    "e28 = Entry(master)\n",
    "e29= Entry(master)\n",
    "\n",
    "e1.grid(row=1, column=1)\n",
    "e2.grid(row=2, column=1)\n",
    "e3.grid(row=3, column=1)\n",
    "e4.grid(row=4, column=1)\n",
    "e5.grid(row=5, column=1)\n",
    "e6.grid(row=6, column=1)\n",
    "\n",
    "e7.grid(row=7, column=1)\n",
    "e8.grid(row=8, column=1)\n",
    "e9.grid(row=9, column=1)\n",
    "e10.grid(row=10, column=1)\n",
    "e11.grid(row=11, column=1)\n",
    "e12.grid(row=12, column=1)\n",
    "\n",
    "\n",
    "e13.grid(row=13, column=1)\n",
    "e14.grid(row=14, column=1)\n",
    "e15.grid(row=15, column=1)\n",
    "e16.grid(row=16, column=1)\n",
    "e17.grid(row=17, column=1)\n",
    "e18.grid(row=18, column=1)\n",
    "\n",
    "\n",
    "e19.grid(row=19, column=1)\n",
    "e20.grid(row=20, column=1)\n",
    "e21.grid(row=21, column=1)\n",
    "e22.grid(row=22, column=1)\n",
    "e23.grid(row=23, column=1)\n",
    "e24.grid(row=24, column=1)\n",
    "\n",
    "e25.grid(row=25, column=1)\n",
    "e26.grid(row=26, column=1)\n",
    "e27.grid(row=27, column=1)\n",
    "e28.grid(row=28, column=1)\n",
    "e29.grid(row=29, column=1)\n",
    " \n",
    "Button(master, text='Predict', command=show_entry_fields).grid(row=30, column=1, sticky=W, pady=4)\n",
    "\n",
    "mainloop( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
